{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a837f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0f113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4cd519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7170879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n",
      "ðŸ“Š XGBoost version: 3.0.2\n",
      "ðŸ”§ Configuration loaded:\n",
      "   GOOGLE_API_KEY: Set\n",
      "   WEATHER_API_KEY: Set\n",
      "   USE_SIMULATED_DATA: False\n",
      "   TRAINING_SAMPLES_PER_ROUTE: 50\n",
      "   RANDOM_SEED: 42\n",
      "============================================================\n",
      "STARTING DATA COLLECTION FROM DELIVERY FORMAT\n",
      "============================================================\n",
      "ðŸ”„ Generating training data from delivery format...\n",
      "ðŸ“ Generated 8 potential delivery routes\n",
      "ðŸŽ‰ Training data generation completed! Collected 0 samples\n",
      "ðŸ’¾ Training data saved to 'udupi_delivery_travel_time_data.csv'\n",
      "\n",
      "============================================================\n",
      "EXPLORATORY DATA ANALYSIS\n",
      "============================================================\n",
      "ðŸ“Š Dataset Overview:\n",
      "   â€¢ Total samples: 0\n",
      "   â€¢ Features: -1\n",
      "   â€¢ Date range: 0 samples\n",
      "   â€¢ Memory usage: 0.0 MB\n",
      "\n",
      "ðŸ“ˆ Travel Time Statistics:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'travel_time_minutes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'travel_time_minutes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 466\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   â€¢ Memory usage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_df\u001b[38;5;241m.\u001b[39mmemory_usage(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“ˆ Travel Time Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 466\u001b[0m \u001b[38;5;28mprint\u001b[39m(training_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtravel_time_minutes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“¦ Package Weight Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28mprint\u001b[39m(training_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpackage_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'travel_time_minutes'"
     ]
    }
   ],
   "source": [
    "# Travel Time Prediction Model Training for Udupi Delivery Routes\n",
    "# Modified to work with the specified delivery data format\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"ðŸ“Š XGBoost version: {xgb.__version__}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 1: CONFIGURATION AND SETUP\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'GOOGLE_API_KEY': \"AIzaSyCAWRHOBP5MGK1kXDc3vEGPJi-SC1zNkuc\",  # Add your Google Maps API key here\n",
    "    'WEATHER_API_KEY': 'b10050649695991355ec91d6ca5cc06f', # Add your OpenWeatherMap API key here\n",
    "    'USE_SIMULATED_DATA': False,  # Set to False when you have real API keys\n",
    "    'TRAINING_SAMPLES_PER_ROUTE': 50,\n",
    "    'RANDOM_SEED': 42\n",
    "}\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(CONFIG['RANDOM_SEED'])\n",
    "\n",
    "print(\"ðŸ”§ Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    if 'API_KEY' in key:\n",
    "        print(f\"   {key}: {'Set' if value else 'Not Set'}\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 2: DATA COLLECTION FUNCTIONS (UPDATED FOR DELIVERY FORMAT)\n",
    "# =============================================================================\n",
    "\n",
    "def get_google_maps_travel_time(origin_lat: float, origin_lng: float,\n",
    "                               dest_lat: float, dest_lng: float,\n",
    "                               departure_time: datetime.datetime,\n",
    "                               api_key: Optional[str] = None) -> Optional[float]:\n",
    "    \"\"\"Get travel time from Google Maps Distance Matrix API.\"\"\"\n",
    "    \n",
    "    if not api_key or CONFIG['USE_SIMULATED_DATA']:\n",
    "        # Simulate realistic travel times for Udupi\n",
    "        distance_deg = np.sqrt((origin_lat - dest_lat)**2 + (origin_lng - dest_lng)**2)\n",
    "        distance_km = distance_deg * 111  # Rough conversion to km\n",
    "        \n",
    "        # Base travel time (assuming 25 km/h average speed in city)\n",
    "        base_time = (distance_km / 25) * 60  # minutes\n",
    "        \n",
    "        # Add time-based factors\n",
    "        hour = departure_time.hour\n",
    "        day_of_week = departure_time.weekday()\n",
    "        \n",
    "        # Rush hour multiplier\n",
    "        if (7 <= hour <= 9) or (17 <= hour <= 19):\n",
    "            time_multiplier = 1.5\n",
    "        elif (22 <= hour <= 6):  # Night time\n",
    "            time_multiplier = 0.8\n",
    "        else:\n",
    "            time_multiplier = 1.0\n",
    "        \n",
    "        # Weekend factor\n",
    "        if day_of_week >= 5:  # Weekend\n",
    "            time_multiplier *= 0.9\n",
    "        \n",
    "        # Weather factor (random)\n",
    "        weather_factor = np.random.uniform(0.9, 1.3)\n",
    "        \n",
    "        # Package weight factor (added for delivery format)\n",
    "        # Assuming average weight is 3kg, with max impact of Â±15%\n",
    "        weight_factor = 1.0  # Will be set in create_features()\n",
    "        \n",
    "        # Calculate final time with some randomness\n",
    "        travel_time = base_time * time_multiplier * weather_factor * weight_factor\n",
    "        travel_time += np.random.normal(0, travel_time * 0.1)  # 10% noise\n",
    "        \n",
    "        return max(1.0, travel_time)\n",
    "    \n",
    "    try:\n",
    "        url = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n",
    "        params = {\n",
    "            'origins': f\"{origin_lat},{origin_lng}\",\n",
    "            'destinations': f\"{dest_lat},{dest_lng}\",\n",
    "            'departure_time': int(departure_time.timestamp()),\n",
    "            'traffic_model': 'best_guess',\n",
    "            'key': api_key\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] == 'OK' and data['rows'][0]['elements'][0]['status'] == 'OK':\n",
    "            duration_in_traffic = data['rows'][0]['elements'][0].get('duration_in_traffic', \n",
    "                                data['rows'][0]['elements'][0]['duration'])\n",
    "            return duration_in_traffic['value'] / 60  # Convert to minutes\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Google Maps API error: {e}\")\n",
    "        # Fall back to simulated data if API fails\n",
    "        return get_google_maps_travel_time(\n",
    "            origin_lat, origin_lng, dest_lat, dest_lng,\n",
    "            departure_time, None  # Force simulated data\n",
    "        )\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_weather_data(lat: float, lng: float, timestamp: datetime.datetime,\n",
    "                    api_key: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Get weather data for the given location and time.\"\"\"\n",
    "    \n",
    "    if not api_key or CONFIG['USE_SIMULATED_DATA']:\n",
    "        # Generate realistic simulated weather for Udupi\n",
    "        # Udupi climate: tropical, warm, humid\n",
    "        \n",
    "        month = timestamp.month\n",
    "        hour = timestamp.hour\n",
    "        \n",
    "        # Temperature varies by month and time\n",
    "        if month in [12, 1, 2]:  # Winter\n",
    "            base_temp = np.random.normal(24, 3)\n",
    "        elif month in [3, 4, 5]:  # Summer\n",
    "            base_temp = np.random.normal(30, 4)\n",
    "        elif month in [6, 7, 8, 9]:  # Monsoon\n",
    "            base_temp = np.random.normal(26, 2)\n",
    "        else:  # Post-monsoon\n",
    "            base_temp = np.random.normal(28, 3)\n",
    "        \n",
    "        # Daily temperature variation\n",
    "        if 6 <= hour <= 8:  # Morning\n",
    "            temp_adjustment = -2\n",
    "        elif 12 <= hour <= 15:  # Afternoon\n",
    "            temp_adjustment = 3\n",
    "        elif 18 <= hour <= 20:  # Evening\n",
    "            temp_adjustment = 0\n",
    "        else:  # Night\n",
    "            temp_adjustment = -1\n",
    "        \n",
    "        temperature = base_temp + temp_adjustment\n",
    "        \n",
    "        # Humidity (high in coastal areas)\n",
    "        humidity = np.random.randint(65, 95)\n",
    "        \n",
    "        # Weather conditions\n",
    "        if month in [6, 7, 8, 9]:  # Monsoon season\n",
    "            weather_condition = np.random.choice(['rain', 'clouds', 'clear'], p=[0.4, 0.4, 0.2])\n",
    "        else:\n",
    "            weather_condition = np.random.choice(['clear', 'clouds', 'rain'], p=[0.6, 0.3, 0.1])\n",
    "        \n",
    "        return {\n",
    "            'temperature': round(temperature, 1),\n",
    "            'humidity': humidity,\n",
    "            'weather_condition': weather_condition,\n",
    "            'wind_speed': np.random.exponential(3),\n",
    "            'visibility': np.random.normal(8, 2) if weather_condition == 'rain' else np.random.normal(12, 2)\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/weather\"\n",
    "        params = {\n",
    "            'lat': lat,\n",
    "            'lon': lng,\n",
    "            'appid': api_key,\n",
    "            'units': 'metric'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return {\n",
    "                'temperature': data['main']['temp'],\n",
    "                'humidity': data['main']['humidity'],\n",
    "                'weather_condition': data['weather'][0]['main'].lower(),\n",
    "                'wind_speed': data['wind']['speed'],\n",
    "                'visibility': data.get('visibility', 10000) / 1000\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Weather API error: {e}\")\n",
    "    \n",
    "    # Fallback\n",
    "    return {\n",
    "        'temperature': 25,\n",
    "        'humidity': 70,\n",
    "        'weather_condition': 'clear',\n",
    "        'wind_speed': 3,\n",
    "        'visibility': 10\n",
    "    }\n",
    "\n",
    "def create_features(origin_lat: float, origin_lng: float,\n",
    "                   dest_lat: float, dest_lng: float,\n",
    "                   timestamp: datetime.datetime,\n",
    "                   weather_data: Dict[str, Any],\n",
    "                   package_weight: float = 3.0) -> Dict[str, Any]:\n",
    "    \"\"\"Create feature vector from raw data, updated for delivery format.\"\"\"\n",
    "    \n",
    "    # Distance features\n",
    "    distance_km = np.sqrt((origin_lat - dest_lat)**2 + (origin_lng - dest_lng)**2) * 111\n",
    "    \n",
    "    # Time features\n",
    "    hour = timestamp.hour\n",
    "    day_of_week = timestamp.weekday()\n",
    "    month = timestamp.month\n",
    "    is_weekend = 1 if day_of_week >= 5 else 0\n",
    "    is_rush_hour = 1 if (7 <= hour <= 9) or (17 <= hour <= 19) else 0\n",
    "    is_night = 1 if (22 <= hour <= 6) else 0\n",
    "    \n",
    "    # Location features\n",
    "    center_lat = (origin_lat + dest_lat) / 2\n",
    "    center_lng = (origin_lng + dest_lng) / 2\n",
    "    \n",
    "    # Direction features\n",
    "    lat_diff = dest_lat - origin_lat\n",
    "    lng_diff = dest_lng - origin_lng\n",
    "    \n",
    "    # Package weight factor (new for delivery format)\n",
    "    # Weight impact: 0-5kg = 1.0, 5-10kg = 1.1, 10+kg = 1.2\n",
    "    if package_weight < 5:\n",
    "        weight_factor = 1.0\n",
    "    elif package_weight < 10:\n",
    "        weight_factor = 1.1\n",
    "    else:\n",
    "        weight_factor = 1.2\n",
    "    \n",
    "    return {\n",
    "        'origin_lat': origin_lat,\n",
    "        'origin_lng': origin_lng,\n",
    "        'dest_lat': dest_lat,\n",
    "        'dest_lng': dest_lng,\n",
    "        'distance_km': distance_km,\n",
    "        'center_lat': center_lat,\n",
    "        'center_lng': center_lng,\n",
    "        'lat_diff': lat_diff,\n",
    "        'lng_diff': lng_diff,\n",
    "        'hour': hour,\n",
    "        'day_of_week': day_of_week,\n",
    "        'month': month,\n",
    "        'is_weekend': is_weekend,\n",
    "        'is_rush_hour': is_rush_hour,\n",
    "        'is_night': is_night,\n",
    "        'temperature': weather_data['temperature'],\n",
    "        'humidity': weather_data['humidity'],\n",
    "        'weather_condition': weather_data['weather_condition'],\n",
    "        'wind_speed': weather_data['wind_speed'],\n",
    "        'visibility': weather_data['visibility'],\n",
    "        'package_weight': package_weight,\n",
    "        'weight_factor': weight_factor\n",
    "    }\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 3: DATA COLLECTION FROM DELIVERY FORMAT\n",
    "# =============================================================================\n",
    "\n",
    "def generate_training_data_from_delivery_format(delivery_data: Dict[str, Any], \n",
    "                                             samples_per_route: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"Generate training data from the delivery data format.\"\"\"\n",
    "    \n",
    "    print(\"ðŸ”„ Generating training data from delivery format...\")\n",
    "    \n",
    "    training_data = []\n",
    "    delivery_persons = delivery_data['delivery_persons']\n",
    "    deliveries = delivery_data['deliveries']\n",
    "    \n",
    "    # Create all possible delivery person to delivery combinations\n",
    "    routes = []\n",
    "    for dp in delivery_persons:\n",
    "        for delivery in deliveries:\n",
    "            routes.append({\n",
    "                'origin_lat': dp['location']['lat'],\n",
    "                'origin_lng': dp['location']['lng'],\n",
    "                'dest_lat': delivery['location']['lat'],\n",
    "                'dest_lng': delivery['location']['lng'],\n",
    "                'package_weight': delivery['package_details']['weight']\n",
    "            })\n",
    "    \n",
    "    print(f\"ðŸ“ Generated {len(routes)} potential delivery routes\")\n",
    "    \n",
    "    # Generate samples for each route\n",
    "    base_date = datetime.datetime.now() - datetime.timedelta(days=60)\n",
    "    \n",
    "    for route_idx, route in enumerate(routes):\n",
    "        if (route_idx + 1) % 10 == 0:\n",
    "            print(f\"   Processing route {route_idx + 1}/{len(routes)}...\")\n",
    "        \n",
    "        for sample_idx in range(samples_per_route):\n",
    "            # Sample random time within last 60 days\n",
    "            sample_time = base_date + datetime.timedelta(\n",
    "                days=np.random.randint(0, 60),\n",
    "                hours=np.random.randint(6, 22),  # Business hours\n",
    "                minutes=np.random.randint(0, 60)\n",
    "            )\n",
    "            \n",
    "            # Get travel time (will fall back to simulated if API fails)\n",
    "            travel_time = get_google_maps_travel_time(\n",
    "                route['origin_lat'], route['origin_lng'],\n",
    "                route['dest_lat'], route['dest_lng'],\n",
    "                sample_time, CONFIG['GOOGLE_API_KEY']\n",
    "            )\n",
    "            \n",
    "            if travel_time is None:\n",
    "                continue\n",
    "            \n",
    "            # Get weather data (will fall back to simulated if API fails)\n",
    "            weather_data = get_weather_data(\n",
    "                route['origin_lat'], route['origin_lng'],\n",
    "                sample_time, CONFIG['WEATHER_API_KEY']\n",
    "            )\n",
    "            \n",
    "            # Create features with package weight\n",
    "            features = create_features(\n",
    "                route['origin_lat'], route['origin_lng'],\n",
    "                route['dest_lat'], route['dest_lng'],\n",
    "                sample_time, weather_data,\n",
    "                route['package_weight']\n",
    "            )\n",
    "            features['travel_time_minutes'] = travel_time\n",
    "            features['route_id'] = route_idx\n",
    "            \n",
    "            training_data.append(features)\n",
    "    \n",
    "    if not training_data:\n",
    "        print(\"âš ï¸ Warning: No data was collected. Falling back to simulated data.\")\n",
    "        CONFIG['USE_SIMULATED_DATA'] = True\n",
    "        return generate_training_data_from_delivery_format(delivery_data, samples_per_route)\n",
    "    \n",
    "    df = pd.DataFrame(training_data)\n",
    "    print(f\"ðŸŽ‰ Training data generation completed! Collected {len(df)} samples\")\n",
    "    \n",
    "    return df\n",
    "# Sample delivery data in the specified format\n",
    "SAMPLE_DELIVERY_DATA = {\n",
    "    \"delivery_persons\": [\n",
    "        {\n",
    "            \"id\": \"dp1\",\n",
    "            \"name\": \"John Doe\",\n",
    "            \"location\": {\n",
    "                \"lat\": 13.3409,\n",
    "                \"lng\": 74.7421\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"dp2\",\n",
    "            \"name\": \"Jane Smith\",\n",
    "            \"location\": {\n",
    "                \"lat\": 13.3506,\n",
    "                \"lng\": 74.7587\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"current_time\": \"2025-04-27T09:00:00\",\n",
    "    \"deliveries\": [\n",
    "        {\n",
    "            \"id\": \"del1\",\n",
    "            \"customer\": \"Customer A\",\n",
    "            \"location\": {\n",
    "                \"lat\": 13.3512,\n",
    "                \"lng\": 74.7403,\n",
    "                \"address\": \"123 Main St, Udupi\"\n",
    "            },\n",
    "            \"time_window\": {\n",
    "                \"start\": \"2025-04-27T10:00:00\",\n",
    "                \"end\": \"2025-04-27T12:00:00\"\n",
    "            },\n",
    "            \"package_details\": {\n",
    "                \"weight\": 2.5,\n",
    "                \"description\": \"Small package\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"del2\",\n",
    "            \"customer\": \"Customer B\",\n",
    "            \"location\": {\n",
    "                \"lat\": 13.3601,\n",
    "                \"lng\": 74.7501,\n",
    "                \"address\": \"456 Market St, Udupi\"\n",
    "            },\n",
    "            \"time_window\": {\n",
    "                \"start\": \"2025-04-27T11:00:00\",\n",
    "                \"end\": \"2025-04-27T13:00:00\"\n",
    "            },\n",
    "            \"package_details\": {\n",
    "                \"weight\": 5.0,\n",
    "                \"description\": \"Medium package\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"del3\",\n",
    "            \"customer\": \"Customer C\",\n",
    "            \"location\": {\n",
    "                \"lat\": 13.3350,\n",
    "                \"lng\": 74.7550,\n",
    "                \"address\": \"789 Park Ave, Udupi\"\n",
    "            },\n",
    "            \"time_window\": {\n",
    "                \"start\": \"2025-04-27T09:30:00\",\n",
    "                \"end\": \"2025-04-27T11:30:00\"\n",
    "            },\n",
    "            \"package_details\": {\n",
    "                \"weight\": 1.2,\n",
    "                \"description\": \"Small package\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"id\": \"del4\",\n",
    "            \"customer\": \"Customer D\",\n",
    "            \"location\": {\n",
    "                \"lat\": 13.3450,\n",
    "                \"lng\": 74.7650,\n",
    "                \"address\": \"101 Beach Rd, Udupi\"\n",
    "            },\n",
    "            \"time_window\": {\n",
    "                \"start\": \"2025-04-27T12:00:00\",\n",
    "                \"end\": \"2025-04-27T14:00:00\"\n",
    "            },\n",
    "            \"package_details\": {\n",
    "                \"weight\": 7.5,\n",
    "                \"description\": \"Large package\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Collect the training data\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING DATA COLLECTION FROM DELIVERY FORMAT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "training_df = generate_training_data_from_delivery_format(\n",
    "    SAMPLE_DELIVERY_DATA, \n",
    "    CONFIG['TRAINING_SAMPLES_PER_ROUTE']\n",
    ")\n",
    "\n",
    "# Save raw data\n",
    "training_df.to_csv('udupi_delivery_travel_time_data.csv', index=False)\n",
    "print(f\"ðŸ’¾ Training data saved to 'udupi_delivery_travel_time_data.csv'\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 4: EXPLORATORY DATA ANALYSIS (UPDATED FOR DELIVERY FEATURES)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"ðŸ“Š Dataset Overview:\")\n",
    "print(f\"   â€¢ Total samples: {len(training_df)}\")\n",
    "print(f\"   â€¢ Features: {len(training_df.columns) - 1}\")\n",
    "print(f\"   â€¢ Date range: {training_df.shape[0]} samples\")\n",
    "print(f\"   â€¢ Memory usage: {training_df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Travel Time Statistics:\")\n",
    "print(training_df['travel_time_minutes'].describe())\n",
    "\n",
    "print(\"\\nðŸ“¦ Package Weight Statistics:\")\n",
    "print(training_df['package_weight'].describe())\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Udupi Delivery Route Travel Time Analysis', fontsize=16)\n",
    "\n",
    "# 1. Travel time distribution\n",
    "axes[0, 0].hist(training_df['travel_time_minutes'], bins=50, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].axvline(training_df['travel_time_minutes'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {training_df[\"travel_time_minutes\"].mean():.1f} min')\n",
    "axes[0, 0].set_xlabel('Travel Time (minutes)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Travel Time Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Travel time by package weight\n",
    "weight_bins = pd.cut(training_df['package_weight'], bins=[0, 2, 5, 10, 20])\n",
    "weight_avg = training_df.groupby(weight_bins)['travel_time_minutes'].mean()\n",
    "axes[0, 1].bar(weight_avg.index.astype(str), weight_avg.values, color='lightgreen')\n",
    "axes[0, 1].set_xlabel('Package Weight (kg)')\n",
    "axes[0, 1].set_ylabel('Average Travel Time (min)')\n",
    "axes[0, 1].set_title('Travel Time by Package Weight')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Travel time by hour\n",
    "hourly_avg = training_df.groupby('hour')['travel_time_minutes'].mean()\n",
    "axes[0, 2].plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2)\n",
    "axes[0, 2].set_xlabel('Hour of Day')\n",
    "axes[0, 2].set_ylabel('Average Travel Time (min)')\n",
    "axes[0, 2].set_title('Travel Time by Hour')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Distance vs travel time\n",
    "axes[1, 0].scatter(training_df['distance_km'], training_df['travel_time_minutes'], alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Distance (km)')\n",
    "axes[1, 0].set_ylabel('Travel Time (minutes)')\n",
    "axes[1, 0].set_title('Distance vs Travel Time')\n",
    "\n",
    "# 5. Weather impact\n",
    "weather_avg = training_df.groupby('weather_condition')['travel_time_minutes'].mean()\n",
    "axes[1, 1].bar(weather_avg.index, weather_avg.values, color='lightcoral')\n",
    "axes[1, 1].set_xlabel('Weather Condition')\n",
    "axes[1, 1].set_ylabel('Average Travel Time (min)')\n",
    "axes[1, 1].set_title('Travel Time by Weather')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Package weight vs travel time\n",
    "axes[1, 2].scatter(training_df['package_weight'], training_df['travel_time_minutes'], alpha=0.5, color='purple')\n",
    "axes[1, 2].set_xlabel('Package Weight (kg)')\n",
    "axes[1, 2].set_ylabel('Travel Time (minutes)')\n",
    "axes[1, 2].set_title('Package Weight vs Travel Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\nðŸ”— Feature Correlations with Travel Time:\")\n",
    "correlations = training_df.corr()['travel_time_minutes'].sort_values(ascending=False)\n",
    "for feature, corr in correlations.items():\n",
    "    if feature != 'travel_time_minutes':\n",
    "        print(f\"   {feature:20s}: {corr:6.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 5: DATA PREPROCESSING (UPDATED FOR DELIVERY FEATURES)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, StandardScaler, Dict]:\n",
    "    \"\"\"Preprocess the training data.\"\"\"\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(['travel_time_minutes', 'route_id'], axis=1)\n",
    "    y = df['travel_time_minutes']\n",
    "    \n",
    "    print(f\"ðŸ”§ Original features: {X.shape[1]}\")\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    label_encoders = {}\n",
    "    categorical_columns = ['weather_condition']\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in X.columns:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "            print(f\"   âœ… Encoded {col}: {len(le.classes_)} categories\")\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X), \n",
    "        columns=X.columns, \n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    print(f\"   âœ… Scaled {X.shape[1]} numerical features\")\n",
    "    print(f\"ðŸŽ¯ Target variable: {y.name} (shape: {y.shape})\")\n",
    "    \n",
    "    return X_scaled, y, scaler, label_encoders\n",
    "\n",
    "# Preprocess the data\n",
    "X_processed, y_processed, feature_scaler, encoders = preprocess_data(training_df)\n",
    "\n",
    "print(f\"\\nðŸ“Š Processed Dataset Shape: {X_processed.shape}\")\n",
    "print(f\"ðŸ“Š Feature Names: {list(X_processed.columns)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 6: MODEL TRAINING AND COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL TRAINING AND COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_processed, test_size=0.2, random_state=CONFIG['RANDOM_SEED']\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Training set: {X_train.shape}\")\n",
    "print(f\"ðŸ“Š Test set: {X_test.shape}\")\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=CONFIG['RANDOM_SEED'],\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        random_state=CONFIG['RANDOM_SEED'],\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'LightGBM': lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=CONFIG['RANDOM_SEED'],\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸ¤– Training {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, \n",
    "                               scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    cv_mae = -cv_scores.mean()\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2,\n",
    "        'cv_mae': cv_mae,\n",
    "        'predictions': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"   âœ… {name} Results:\")\n",
    "    print(f\"      â€¢ Train MAE: {train_mae:.2f} min\")\n",
    "    print(f\"      â€¢ Test MAE:  {test_mae:.2f} min\")\n",
    "    print(f\"      â€¢ Test RMSE: {test_rmse:.2f} min\")\n",
    "    print(f\"      â€¢ Test RÂ²:   {test_r2:.3f}\")\n",
    "    print(f\"      â€¢ CV MAE:    {cv_mae:.2f} min\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 7: MODEL COMPARISON AND SELECTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON AND SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test MAE': [results[model]['test_mae'] for model in results.keys()],\n",
    "    'Test RMSE': [results[model]['test_rmse'] for model in results.keys()],\n",
    "    'Test RÂ²': [results[model]['test_r2'] for model in results.keys()],\n",
    "    'CV MAE': [results[model]['cv_mae'] for model in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"ðŸ† Model Comparison:\")\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Select best model based on test MAE\n",
    "best_model_name = comparison_df.loc[comparison_df['Test MAE'].idxmin(), 'Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nðŸ¥‡ Best Model: {best_model_name}\")\n",
    "print(f\"   â€¢ Test MAE: {results[best_model_name]['test_mae']:.2f} minutes\")\n",
    "print(f\"   â€¢ Test RÂ²: {results[best_model_name]['test_r2']:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 8: MODEL ANALYSIS AND VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL ANALYSIS AND VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Feature importance (for tree-based models)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_processed.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"ðŸ” Top 10 Most Important Features:\")\n",
    "    for idx, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"   {row['feature']:20s}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    top_features = feature_importance.head(10)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "# Prediction vs Actual plot\n",
    "plt.subplot(2, 2, 2)\n",
    "y_pred_best = results[best_model_name]['predictions']\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Travel Time (min)')\n",
    "plt.ylabel('Predicted Travel Time (min)')\n",
    "plt.title(f'{best_model_name}: Predictions vs Actual')\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(2, 2, 3)\n",
    "residuals = y_test - y_pred_best\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Travel Time (min)')\n",
    "plt.ylabel('Residuals (min)')\n",
    "plt.title('Residuals Plot')\n",
    "\n",
    "# Model comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "model_names = list(results.keys())\n",
    "test_maes = [results[model]['test_mae'] for model in model_names]\n",
    "plt.bar(model_names, test_maes, color=['gold' if model == best_model_name else 'lightblue' for model in model_names])\n",
    "plt.ylabel('Test MAE (minutes)')\n",
    "plt.title('Model Comparison (Test MAE)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 9: SAVE THE BEST MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING THE BEST MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create model package\n",
    "model_package = {\n",
    "    'model': best_model,\n",
    "    'scaler': feature_scaler,\n",
    "    'label_encoders': encoders,\n",
    "    'feature_columns': list(X_processed.columns),\n",
    "    'model_name': best_model_name,\n",
    "    'training_metrics': {\n",
    "        'test_mae': results[best_model_name]['test_mae'],\n",
    "        'test_rmse': results[best_model_name]['test_rmse'],\n",
    "        'test_r2': results[best_model_name]['test_r2'],\n",
    "        'cv_mae': results[best_model_name]['cv_mae']\n",
    "    },\n",
    "    'training_date': datetime.datetime.now().isoformat(),\n",
    "    'training_samples': len(training_df),\n",
    "    'feature_importance': feature_importance.to_dict('records') if hasattr(best_model, 'feature_importances_') else None\n",
    "}\n",
    "\n",
    "# Save model\n",
    "model_filename = f'udupi_delivery_travel_time_model.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(model_package, f)\n",
    "    \n",
    "print(f\"ðŸ’¾ Model saved to '{model_filename}'\")\n",
    "\n",
    "# =============================================================================\n",
    "# SECTION 10: PREDICTION FUNCTION FOR DELIVERY FORMAT\n",
    "# =============================================================================\n",
    "\n",
    "def predict_travel_time_for_delivery(delivery_data: Dict[str, Any], \n",
    "                                   model_package: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Predict travel times for all delivery person to delivery combinations.\n",
    "    \n",
    "    Args:\n",
    "        delivery_data: The input delivery data in the specified format\n",
    "        model_package: The saved model package\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with predictions for all combinations\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"MAKING PREDICTIONS FOR DELIVERY DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Extract components from model package\n",
    "    model = model_package['model']\n",
    "    scaler = model_package['scaler']\n",
    "    label_encoders = model_package['label_encoders']\n",
    "    feature_columns = model_package['feature_columns']\n",
    "    \n",
    "    # Prepare prediction data\n",
    "    prediction_data = []\n",
    "    prediction_metadata = []\n",
    "    \n",
    "    current_time = datetime.datetime.fromisoformat(delivery_data['current_time'])\n",
    "    \n",
    "    for dp in delivery_data['delivery_persons']:\n",
    "        for delivery in delivery_data['deliveries']:\n",
    "            # Get weather data\n",
    "            weather_data = get_weather_data(\n",
    "                dp['location']['lat'], dp['location']['lng'],\n",
    "                current_time, CONFIG['WEATHER_API_KEY']\n",
    "            )\n",
    "            \n",
    "            # Create features\n",
    "            features = create_features(\n",
    "                dp['location']['lat'], dp['location']['lng'],\n",
    "                delivery['location']['lat'], delivery['location']['lng'],\n",
    "                current_time, weather_data,\n",
    "                delivery['package_details']['weight']\n",
    "            )\n",
    "            \n",
    "            # Store metadata for reference\n",
    "            prediction_metadata.append({\n",
    "                'delivery_person_id': dp['id'],\n",
    "                'delivery_id': delivery['id'],\n",
    "                'origin_lat': dp['location']['lat'],\n",
    "                'origin_lng': dp['location']['lng'],\n",
    "                'dest_lat': delivery['location']['lat'],\n",
    "                'dest_lng': delivery['location']['lng'],\n",
    "                'package_weight': delivery['package_details']['weight']\n",
    "            })\n",
    "            \n",
    "            prediction_data.append(features)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    prediction_df = pd.DataFrame(prediction_data)\n",
    "    \n",
    "    # Preprocess the data (same as training)\n",
    "    X_pred = prediction_df[feature_columns]\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    for col, encoder in label_encoders.items():\n",
    "        X_pred[col] = encoder.transform(X_pred[col].astype(str))\n",
    "    \n",
    "    # Scale numerical features\n",
    "    X_pred_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_pred), \n",
    "        columns=X_pred.columns, \n",
    "        index=X_pred.index\n",
    "    )\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_pred_scaled)\n",
    "    \n",
    "    # Combine results with metadata\n",
    "    results = []\n",
    "    for i, pred in enumerate(predictions):\n",
    "        results.append({\n",
    "            **prediction_metadata[i],\n",
    "            'predicted_travel_time_minutes': float(pred)\n",
    "        })\n",
    "    \n",
    "    # Format output similar to the example\n",
    "    output = {\n",
    "        \"data\": {\n",
    "            \"predictions\": results\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"ðŸ“Š Generated {len(predictions)} predictions\")\n",
    "    return output\n",
    "\n",
    "# Test the prediction function\n",
    "print(\"\\nTesting prediction function with sample delivery data...\")\n",
    "predictions = predict_travel_time_for_delivery(SAMPLE_DELIVERY_DATA, model_package)\n",
    "\n",
    "# Print sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e9aa925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'results': [{'address_components': [{'long_name': 'Udupi', 'short_name': 'Udupi', 'types': ['locality', 'political']}, {'long_name': 'Udupi', 'short_name': 'Udupi', 'types': ['administrative_area_level_3', 'political']}, {'long_name': 'Mysore Division', 'short_name': 'Mysore Division', 'types': ['administrative_area_level_2', 'political']}, {'long_name': 'Karnataka', 'short_name': 'KA', 'types': ['administrative_area_level_1', 'political']}, {'long_name': 'India', 'short_name': 'IN', 'types': ['country', 'political']}], 'formatted_address': 'Udupi, Karnataka, India', 'geometry': {'bounds': {'northeast': {'lat': 13.3685355, 'lng': 74.7834603}, 'southwest': {'lat': 13.2950817, 'lng': 74.7105588}}, 'location': {'lat': 13.3408807, 'lng': 74.7421427}, 'location_type': 'APPROXIMATE', 'viewport': {'northeast': {'lat': 13.3685355, 'lng': 74.7834603}, 'southwest': {'lat': 13.2950817, 'lng': 74.7105588}}}, 'place_id': 'ChIJz0GPk2m7vDsRQwGFMeSZzMw', 'types': ['locality', 'political']}], 'status': 'OK'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "key = \"AIzaSyCAWRHOBP5MGK1kXDc3vEGPJi-SC1zNkuc\"\n",
    "address = \"Udupi, Karnataka\"\n",
    "url = f\"https://maps.googleapis.com/maps/api/geocode/json?address={address}&key={key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "299ba8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coord': {'lon': 74.75, 'lat': 13.35}, 'weather': [{'id': 804, 'main': 'Clouds', 'description': 'overcast clouds', 'icon': '04d'}], 'base': 'stations', 'main': {'temp': 301.08, 'feels_like': 305.23, 'temp_min': 301.08, 'temp_max': 301.08, 'pressure': 1006, 'humidity': 81, 'sea_level': 1006, 'grnd_level': 1004}, 'visibility': 6759, 'wind': {'speed': 7.63, 'deg': 284, 'gust': 10.32}, 'clouds': {'all': 100}, 'dt': 1748334504, 'sys': {'country': 'IN', 'sunrise': 1748306004, 'sunset': 1748352193}, 'timezone': 19800, 'id': 1253952, 'name': 'Udupi', 'cod': 200}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "key = \"b10050649695991355ec91d6ca5cc06f\"\n",
    "city = \"Udupi\"\n",
    "url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={key}\"\n",
    "\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a071d872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ce7d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
