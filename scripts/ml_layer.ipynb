{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1789e8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/29/22/e3ff2dfafe862a91733dfa0aecdb4794aa1d9a18e09a14e118bde0cbc2db/xgboost-3.0.2-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-3.0.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\shriya bhat\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\shriya bhat\\anaconda3\\lib\\site-packages (from xgboost) (1.10.1)\n",
      "Downloading xgboost-3.0.2-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/150.0 MB 6.5 MB/s eta 0:00:23\n",
      "   ---------------------------------------- 0.8/150.0 MB 9.8 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 1.3/150.0 MB 10.4 MB/s eta 0:00:15\n",
      "   ---------------------------------------- 1.8/150.0 MB 10.7 MB/s eta 0:00:14\n",
      "    --------------------------------------- 2.2/150.0 MB 10.0 MB/s eta 0:00:15\n",
      "    --------------------------------------- 2.7/150.0 MB 10.0 MB/s eta 0:00:15\n",
      "    --------------------------------------- 3.1/150.0 MB 10.0 MB/s eta 0:00:15\n",
      "    --------------------------------------- 3.5/150.0 MB 9.7 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 3.9/150.0 MB 10.0 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 4.4/150.0 MB 9.8 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 4.8/150.0 MB 9.9 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 4.9/150.0 MB 9.5 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 5.4/150.0 MB 9.0 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 5.8/150.0 MB 9.0 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 6.2/150.0 MB 8.9 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 6.5/150.0 MB 8.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 6.9/150.0 MB 8.8 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 7.3/150.0 MB 8.8 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 7.7/150.0 MB 8.8 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 8.1/150.0 MB 8.7 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 8.6/150.0 MB 8.9 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 9.0/150.0 MB 8.9 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 9.5/150.0 MB 8.8 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 10.0/150.0 MB 9.0 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 10.4/150.0 MB 9.0 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 10.8/150.0 MB 8.8 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 11.2/150.0 MB 9.0 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 11.7/150.0 MB 8.7 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 12.1/150.0 MB 8.7 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 12.6/150.0 MB 8.8 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 13.1/150.0 MB 8.8 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 13.5/150.0 MB 8.7 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 14.0/150.0 MB 8.7 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 14.4/150.0 MB 8.7 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 14.9/150.0 MB 8.8 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 15.4/150.0 MB 9.2 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 15.9/150.0 MB 9.2 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 16.4/150.0 MB 9.4 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 16.9/150.0 MB 9.4 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 17.3/150.0 MB 9.5 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 17.7/150.0 MB 9.6 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 18.1/150.0 MB 9.6 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 18.5/150.0 MB 9.6 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 18.9/150.0 MB 9.6 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 19.3/150.0 MB 9.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 19.9/150.0 MB 9.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 20.4/150.0 MB 9.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 20.9/150.0 MB 9.9 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 21.4/150.0 MB 10.1 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 21.8/150.0 MB 10.1 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 22.2/150.0 MB 10.1 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 22.7/150.0 MB 10.2 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 23.1/150.0 MB 10.2 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 23.6/150.0 MB 10.2 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 24.0/150.0 MB 10.4 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 24.6/150.0 MB 10.4 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 25.0/150.0 MB 10.4 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 25.6/150.0 MB 10.4 MB/s eta 0:00:12\n",
      "   ------ --------------------------------- 26.1/150.0 MB 10.4 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 26.6/150.0 MB 10.7 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 27.2/150.0 MB 10.6 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 27.7/150.0 MB 10.7 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 28.2/150.0 MB 10.7 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 28.8/150.0 MB 10.7 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 29.3/150.0 MB 10.9 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 29.9/150.0 MB 10.9 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 30.3/150.0 MB 11.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 30.9/150.0 MB 10.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 31.4/150.0 MB 10.9 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 32.0/150.0 MB 11.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 32.6/150.0 MB 11.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 33.1/150.0 MB 11.1 MB/s eta 0:00:11\n",
      "   -------- ------------------------------- 33.4/150.0 MB 10.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 33.8/150.0 MB 10.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 34.2/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 34.8/150.0 MB 10.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 35.3/150.0 MB 10.9 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 35.8/150.0 MB 10.7 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 36.3/150.0 MB 10.7 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 36.8/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 37.2/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 37.8/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 38.2/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 38.7/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 39.2/150.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 39.6/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 40.1/150.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 40.7/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 41.2/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 41.7/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 42.2/150.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 42.8/150.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 43.2/150.0 MB 10.4 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 43.7/150.0 MB 10.7 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 44.2/150.0 MB 10.6 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 44.6/150.0 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 45.2/150.0 MB 10.7 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 45.8/150.0 MB 10.6 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 46.3/150.0 MB 10.7 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 46.9/150.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 47.4/150.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 47.9/150.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 48.4/150.0 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 48.9/150.0 MB 10.7 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 49.5/150.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 49.9/150.0 MB 11.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 50.5/150.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 51.1/150.0 MB 10.9 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 51.4/150.0 MB 10.7 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 52.0/150.0 MB 10.7 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 52.4/150.0 MB 10.7 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 52.8/150.0 MB 10.6 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 53.2/150.0 MB 10.6 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 53.8/150.0 MB 10.6 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 54.4/150.0 MB 10.6 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 54.9/150.0 MB 10.9 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 55.4/150.0 MB 10.7 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 56.1/150.0 MB 10.7 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 56.4/150.0 MB 10.6 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 56.9/150.0 MB 10.4 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 57.4/150.0 MB 10.4 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 57.9/150.0 MB 10.4 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 58.6/150.0 MB 10.4 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 59.1/150.0 MB 10.4 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 59.6/150.0 MB 10.2 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 60.2/150.0 MB 10.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 60.7/150.0 MB 10.2 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 61.1/150.0 MB 10.4 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 61.6/150.0 MB 10.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 62.2/150.0 MB 10.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 62.7/150.0 MB 10.6 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 63.2/150.0 MB 10.7 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 63.6/150.0 MB 10.7 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 64.2/150.0 MB 10.7 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 64.7/150.0 MB 10.7 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 65.0/150.0 MB 10.7 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 65.6/150.0 MB 10.7 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 66.1/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 66.6/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 67.2/150.0 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 67.7/150.0 MB 10.9 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 68.2/150.0 MB 11.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 68.6/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 69.1/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 69.4/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 69.9/150.0 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 70.4/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 71.0/150.0 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 71.3/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 71.9/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 72.4/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 72.8/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 73.3/150.0 MB 10.7 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 73.7/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 74.2/150.0 MB 10.6 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 74.7/150.0 MB 10.7 MB/s eta 0:00:08\n",
      "   -------------------- ------------------- 75.1/150.0 MB 10.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 75.6/150.0 MB 10.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 76.1/150.0 MB 10.6 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 76.6/150.0 MB 10.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 77.1/150.0 MB 10.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 77.6/150.0 MB 10.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 78.2/150.0 MB 10.7 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 78.6/150.0 MB 10.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 79.1/150.0 MB 10.7 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 79.5/150.0 MB 10.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 80.1/150.0 MB 10.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 80.5/150.0 MB 10.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 81.0/150.0 MB 10.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 81.5/150.0 MB 10.9 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 82.0/150.0 MB 10.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 82.6/150.0 MB 11.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 83.1/150.0 MB 11.1 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 83.6/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 84.1/150.0 MB 10.9 MB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 84.6/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 85.1/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 85.6/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 86.1/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 86.7/150.0 MB 11.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 87.1/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 87.5/150.0 MB 10.9 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 88.1/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 88.7/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 89.2/150.0 MB 11.3 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 89.7/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 90.1/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 90.6/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 91.1/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 91.6/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 92.1/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 92.5/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 93.1/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 93.6/150.0 MB 11.1 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 94.0/150.0 MB 10.7 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 94.5/150.0 MB 10.9 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 94.9/150.0 MB 10.7 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 95.4/150.0 MB 10.7 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 95.8/150.0 MB 10.6 MB/s eta 0:00:06\n",
      "   ------------------------- -------------- 96.5/150.0 MB 10.7 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 96.8/150.0 MB 10.6 MB/s eta 0:00:06\n",
      "   -------------------------- ------------- 97.5/150.0 MB 10.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 98.1/150.0 MB 10.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 98.9/150.0 MB 10.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 99.6/150.0 MB 11.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 100.2/150.0 MB 10.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 101.0/150.0 MB 10.9 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 101.5/150.0 MB 10.7 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 102.7/150.0 MB 11.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------ 103.4/150.0 MB 11.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 104.1/150.0 MB 11.1 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 104.7/150.0 MB 11.3 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 105.2/150.0 MB 11.3 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 105.7/150.0 MB 11.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 106.5/150.0 MB 11.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 107.0/150.0 MB 11.7 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 107.6/150.0 MB 11.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 108.3/150.0 MB 11.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 108.9/150.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 109.5/150.0 MB 11.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 110.2/150.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 110.8/150.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 111.3/150.0 MB 11.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 112.1/150.0 MB 11.9 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 112.8/150.0 MB 11.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 113.6/150.0 MB 11.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 114.1/150.0 MB 11.5 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 114.9/150.0 MB 11.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 115.6/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 116.3/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 117.1/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 117.8/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 118.5/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 119.1/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 119.6/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 120.2/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 120.8/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 121.3/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 121.8/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 122.4/150.0 MB 11.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 122.9/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 123.4/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 124.0/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 124.5/150.0 MB 11.7 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 125.0/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 125.5/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 126.0/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 126.6/150.0 MB 11.5 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 127.1/150.0 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 127.6/150.0 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 128.0/150.0 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 128.6/150.0 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 129.2/150.0 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 129.6/150.0 MB 11.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 130.2/150.0 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 130.7/150.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 131.2/150.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 131.7/150.0 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 132.2/150.0 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 132.8/150.0 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 133.3/150.0 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 133.8/150.0 MB 10.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 134.2/150.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 134.8/150.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 135.2/150.0 MB 10.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 135.7/150.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 136.3/150.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 136.7/150.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 137.3/150.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 137.7/150.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 138.2/150.0 MB 10.7 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 138.6/150.0 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 139.2/150.0 MB 10.6 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 139.7/150.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 140.2/150.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 140.7/150.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 141.3/150.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 141.9/150.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 142.4/150.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 143.0/150.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 143.5/150.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 144.0/150.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 144.6/150.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 145.1/150.0 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 145.7/150.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  146.3/150.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  146.8/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  147.4/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  147.8/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  148.3/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  148.9/150.0 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.4/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  149.9/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  150.0/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  150.0/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  150.0/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  150.0/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  150.0/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  150.0/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  150.0/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  150.0/150.0 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 150.0/150.0 MB 7.0 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f172b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Obtaining dependency information for lightgbm from https://files.pythonhosted.org/packages/5e/23/f8b28ca248bb629b9e08f877dd2965d1994e1674a03d67cd10c5246da248/lightgbm-4.6.0-py3-none-win_amd64.whl.metadata\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\shriya bhat\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\shriya bhat\\anaconda3\\lib\\site-packages (from lightgbm) (1.10.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.4/1.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 9.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.4/1.5 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 8.4 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "709dd25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Travel Time Prediction Model Training for Udupi Delivery Routes\n",
    "# This notebook trains an ML model to predict travel times for delivery optimization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import datetime\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9399c2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML libraries\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26cf203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de0932da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "XGBoost version: 3.0.2\n"
     ]
    }
   ],
   "source": [
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6131ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 1: CONFIGURATION AND SETUP\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'GOOGLE_API_KEY':'AIzaSyCAWRHOBP5MGK1kXDc3vEGPJi-SC1zNkuc',  # Add your Google Maps API key here\n",
    "    'WEATHER_API_KEY': '1128702f089368cf9384837ca336f183', # Add your OpenWeatherMap API key here\n",
    "    'USE_SIMULATED_DATA': False,  # Set to False when you have real API keys\n",
    "    'TRAINING_SAMPLES_PER_ROUTE': 50,\n",
    "    'RANDOM_SEED': 42\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dde390a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "   GOOGLE_API_KEY: Set\n",
      "   WEATHER_API_KEY: Set\n",
      "   USE_SIMULATED_DATA: False\n",
      "   TRAINING_SAMPLES_PER_ROUTE: 50\n",
      "   RANDOM_SEED: 42\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(CONFIG['RANDOM_SEED'])\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    if 'API_KEY' in key:\n",
    "        print(f\"   {key}: {'Set' if value else 'Not Set'}\")\n",
    "    else:\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca1b04f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 2: DATA COLLECTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_google_maps_travel_time(origin_lat: float, origin_lng: float,\n",
    "                               dest_lat: float, dest_lng: float,\n",
    "                               departure_time: datetime.datetime,\n",
    "                               api_key: Optional[str] = None) -> Optional[float]:\n",
    "    \"\"\"Get travel time from Google Maps Distance Matrix API.\"\"\"\n",
    "    \n",
    "    if not api_key or CONFIG['USE_SIMULATED_DATA']:\n",
    "        # Simulate realistic travel times for Udupi\n",
    "        distance_deg = np.sqrt((origin_lat - dest_lat)**2 + (origin_lng - dest_lng)**2)\n",
    "        distance_km = distance_deg * 111  # Rough conversion to km\n",
    "        \n",
    "        # Base travel time (assuming 25 km/h average speed in city)\n",
    "        base_time = (distance_km / 25) * 60  # minutes\n",
    "        \n",
    "        # Add time-based factors\n",
    "        hour = departure_time.hour\n",
    "        day_of_week = departure_time.weekday()\n",
    "        \n",
    "        # Rush hour multiplier\n",
    "        if (7 <= hour <= 9) or (17 <= hour <= 19):\n",
    "            time_multiplier = 1.5\n",
    "        elif (22 <= hour <= 6):  # Night time\n",
    "            time_multiplier = 0.8\n",
    "        else:\n",
    "            time_multiplier = 1.0\n",
    "        \n",
    "        # Weekend factor\n",
    "        if day_of_week >= 5:  # Weekend\n",
    "            time_multiplier *= 0.9\n",
    "        \n",
    "        # Weather factor (random)\n",
    "        weather_factor = np.random.uniform(0.9, 1.3)\n",
    "        \n",
    "        # Calculate final time with some randomness\n",
    "        travel_time = base_time * time_multiplier * weather_factor\n",
    "        travel_time += np.random.normal(0, travel_time * 0.1)  # 10% noise\n",
    "        \n",
    "        return max(1.0, travel_time)\n",
    "    \n",
    "    try:\n",
    "        url = \"https://maps.googleapis.com/maps/api/distancematrix/json\"\n",
    "        params = {\n",
    "            'origins': f\"{origin_lat},{origin_lng}\",\n",
    "            'destinations': f\"{dest_lat},{dest_lng}\",\n",
    "            'departure_time': int(departure_time.timestamp()),\n",
    "            'traffic_model': 'best_guess',\n",
    "            'key': api_key\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        \n",
    "        if data['status'] == 'OK' and data['rows'][0]['elements'][0]['status'] == 'OK':\n",
    "            duration_in_traffic = data['rows'][0]['elements'][0].get('duration_in_traffic', \n",
    "                                data['rows'][0]['elements'][0]['duration'])\n",
    "            return duration_in_traffic['value'] / 60  # Convert to minutes\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Google Maps API error: {e}\")\n",
    "    \n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0993fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_data(lat: float, lng: float, timestamp: datetime.datetime,\n",
    "                    api_key: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"Get weather data for the given location and time.\"\"\"\n",
    "    \n",
    "    if not api_key or CONFIG['USE_SIMULATED_DATA']:\n",
    "        # Generate realistic simulated weather for Udupi\n",
    "        # Udupi climate: tropical, warm, humid\n",
    "        \n",
    "        month = timestamp.month\n",
    "        hour = timestamp.hour\n",
    "        \n",
    "        # Temperature varies by month and time\n",
    "        if month in [12, 1, 2]:  # Winter\n",
    "            base_temp = np.random.normal(24, 3)\n",
    "        elif month in [3, 4, 5]:  # Summer\n",
    "            base_temp = np.random.normal(30, 4)\n",
    "        elif month in [6, 7, 8, 9]:  # Monsoon\n",
    "            base_temp = np.random.normal(26, 2)\n",
    "        else:  # Post-monsoon\n",
    "            base_temp = np.random.normal(28, 3)\n",
    "        \n",
    "        # Daily temperature variation\n",
    "        if 6 <= hour <= 8:  # Morning\n",
    "            temp_adjustment = -2\n",
    "        elif 12 <= hour <= 15:  # Afternoon\n",
    "            temp_adjustment = 3\n",
    "        elif 18 <= hour <= 20:  # Evening\n",
    "            temp_adjustment = 0\n",
    "        else:  # Night\n",
    "            temp_adjustment = -1\n",
    "        \n",
    "        temperature = base_temp + temp_adjustment\n",
    "        \n",
    "        # Humidity (high in coastal areas)\n",
    "        humidity = np.random.randint(65, 95)\n",
    "        \n",
    "        # Weather conditions\n",
    "        if month in [6, 7, 8, 9]:  # Monsoon season\n",
    "            weather_condition = np.random.choice(['rain', 'clouds', 'clear'], p=[0.4, 0.4, 0.2])\n",
    "        else:\n",
    "            weather_condition = np.random.choice(['clear', 'clouds', 'rain'], p=[0.6, 0.3, 0.1])\n",
    "        \n",
    "        return {\n",
    "            'temperature': round(temperature, 1),\n",
    "            'humidity': humidity,\n",
    "            'weather_condition': weather_condition,\n",
    "            'wind_speed': np.random.exponential(3),\n",
    "            'visibility': np.random.normal(8, 2) if weather_condition == 'rain' else np.random.normal(12, 2)\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        url = f\"http://api.openweathermap.org/data/2.5/weather\"\n",
    "        params = {\n",
    "            'lat': lat,\n",
    "            'lon': lng,\n",
    "            'appid': api_key,\n",
    "            'units': 'metric'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return {\n",
    "                'temperature': data['main']['temp'],\n",
    "                'humidity': data['main']['humidity'],\n",
    "                'weather_condition': data['weather'][0]['main'].lower(),\n",
    "                'wind_speed': data['wind']['speed'],\n",
    "                'visibility': data.get('visibility', 10000) / 1000\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\" Weather API error: {e}\")\n",
    "    \n",
    "    # Fallback\n",
    "    return {\n",
    "        'temperature': 25,\n",
    "        'humidity': 70,\n",
    "        'weather_condition': 'clear',\n",
    "        'wind_speed': 3,\n",
    "        'visibility': 10\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa989afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(origin_lat: float, origin_lng: float,\n",
    "                   dest_lat: float, dest_lng: float,\n",
    "                   timestamp: datetime.datetime,\n",
    "                   weather_data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Create feature vector from raw data.\"\"\"\n",
    "    \n",
    "    # Distance features\n",
    "    distance_km = np.sqrt((origin_lat - dest_lat)**2 + (origin_lng - dest_lng)**2) * 111\n",
    "    \n",
    "    # Time features\n",
    "    hour = timestamp.hour\n",
    "    day_of_week = timestamp.weekday()\n",
    "    month = timestamp.month\n",
    "    is_weekend = 1 if day_of_week >= 5 else 0\n",
    "    is_rush_hour = 1 if (7 <= hour <= 9) or (17 <= hour <= 19) else 0\n",
    "    is_night = 1 if (22 <= hour <= 6) else 0\n",
    "    \n",
    "    # Location features\n",
    "    center_lat = (origin_lat + dest_lat) / 2\n",
    "    center_lng = (origin_lng + dest_lng) / 2\n",
    "    \n",
    "    # Direction features\n",
    "    lat_diff = dest_lat - origin_lat\n",
    "    lng_diff = dest_lng - origin_lng\n",
    "    \n",
    "    return {\n",
    "        'origin_lat': origin_lat,\n",
    "        'origin_lng': origin_lng,\n",
    "        'dest_lat': dest_lat,\n",
    "        'dest_lng': dest_lng,\n",
    "        'distance_km': distance_km,\n",
    "        'center_lat': center_lat,\n",
    "        'center_lng': center_lng,\n",
    "        'lat_diff': lat_diff,\n",
    "        'lng_diff': lng_diff,\n",
    "        'hour': hour,\n",
    "        'day_of_week': day_of_week,\n",
    "        'month': month,\n",
    "        'is_weekend': is_weekend,\n",
    "        'is_rush_hour': is_rush_hour,\n",
    "        'is_night': is_night,\n",
    "        'temperature': weather_data['temperature'],\n",
    "        'humidity': weather_data['humidity'],\n",
    "        'weather_condition': weather_data['weather_condition'],\n",
    "        'wind_speed': weather_data['wind_speed'],\n",
    "        'visibility': weather_data['visibility']\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6ca1283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Defined 18 training routes in Udupi\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 3: DEFINE TRAINING ROUTES\n",
    "# =============================================================================\n",
    "\n",
    "# Define sample delivery routes in Udupi\n",
    "# You should replace these with your actual delivery routes\n",
    "UDUPI_ROUTES = [\n",
    "    # Format: (origin_lat, origin_lng, dest_lat, dest_lng)\n",
    "    \n",
    "    # Main Udupi area routes\n",
    "    (13.3409, 74.7421, 13.3500, 74.7500),  # Central to North\n",
    "    (13.3409, 74.7421, 13.3300, 74.7400),  # Central to South\n",
    "    (13.3409, 74.7421, 13.3450, 74.7350),  # Central to East\n",
    "    (13.3409, 74.7421, 13.3350, 74.7480),  # Central to West\n",
    "    \n",
    "    # Cross-town routes\n",
    "    (13.3500, 74.7500, 13.3300, 74.7400),  # North to South\n",
    "    (13.3450, 74.7350, 13.3350, 74.7480),  # East to West\n",
    "    (13.3600, 74.7550, 13.3250, 74.7350),  # Northeast to Southwest\n",
    "    (13.3250, 74.7450, 13.3550, 74.7380),  # Northwest to Southeast\n",
    "    \n",
    "    # Longer routes (to suburbs/nearby areas)\n",
    "    (13.3409, 74.7421, 13.3700, 74.7600),  # To Manipal area\n",
    "    (13.3409, 74.7421, 13.3100, 74.7300),  # To Malpe area\n",
    "    (13.3409, 74.7421, 13.3200, 74.7600),  # To Karkala road\n",
    "    (13.3409, 74.7421, 13.3600, 74.7200),  # To Kundapur road\n",
    "    \n",
    "    # Market and commercial area routes\n",
    "    (13.3380, 74.7430, 13.3420, 74.7400),  # Market area\n",
    "    (13.3400, 74.7450, 13.3440, 74.7420),  # Commercial district\n",
    "    (13.3360, 74.7410, 13.3480, 74.7440),  # Shopping areas\n",
    "    \n",
    "    # Residential area routes\n",
    "    (13.3320, 74.7380, 13.3520, 74.7520),  # Residential zones\n",
    "    (13.3280, 74.7360, 13.3480, 74.7480),  # Housing societies\n",
    "    (13.3540, 74.7540, 13.3340, 74.7340),  # Apartment complexes\n",
    "]\n",
    "\n",
    "print(f\" Defined {len(UDUPI_ROUTES)} training routes in Udupi\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f10a5bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING DATA COLLECTION\n",
      "============================================================\n",
      "Starting data collection for 18 routes...\n",
      "Collecting 50 samples per route = 900 total samples\n",
      "   Route 1/18: (13.3409, 74.7421) → (13.3500, 74.7500)\n",
      "   Route 2/18: (13.3409, 74.7421) → (13.3300, 74.7400)\n",
      "   Route 3/18: (13.3409, 74.7421) → (13.3450, 74.7350)\n",
      "   Route 4/18: (13.3409, 74.7421) → (13.3350, 74.7480)\n",
      "   Route 5/18: (13.3500, 74.7500) → (13.3300, 74.7400)\n",
      "    Completed 5 routes (0 samples collected)\n",
      "   Route 6/18: (13.3450, 74.7350) → (13.3350, 74.7480)\n",
      "   Route 7/18: (13.3600, 74.7550) → (13.3250, 74.7350)\n",
      "   Route 8/18: (13.3250, 74.7450) → (13.3550, 74.7380)\n",
      "   Route 9/18: (13.3409, 74.7421) → (13.3700, 74.7600)\n",
      "   Route 10/18: (13.3409, 74.7421) → (13.3100, 74.7300)\n",
      "    Completed 10 routes (0 samples collected)\n",
      "   Route 11/18: (13.3409, 74.7421) → (13.3200, 74.7600)\n",
      "   Route 12/18: (13.3409, 74.7421) → (13.3600, 74.7200)\n",
      "   Route 13/18: (13.3380, 74.7430) → (13.3420, 74.7400)\n",
      "   Route 14/18: (13.3400, 74.7450) → (13.3440, 74.7420)\n",
      "   Route 15/18: (13.3360, 74.7410) → (13.3480, 74.7440)\n",
      "    Completed 15 routes (0 samples collected)\n",
      "   Route 16/18: (13.3320, 74.7380) → (13.3520, 74.7520)\n",
      "   Route 17/18: (13.3280, 74.7360) → (13.3480, 74.7480)\n",
      "   Route 18/18: (13.3540, 74.7540) → (13.3340, 74.7340)\n",
      "Data collection completed! Collected 0 samples\n",
      "Training data saved to 'udupi_travel_time_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 4: DATA COLLECTION\n",
    "# =============================================================================\n",
    "\n",
    "def collect_training_data(routes: List[Tuple[float, float, float, float]], \n",
    "                         samples_per_route: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"Collect training data for all routes.\"\"\"\n",
    "    \n",
    "    print(f\"Starting data collection for {len(routes)} routes...\")\n",
    "    print(f\"Collecting {samples_per_route} samples per route = {len(routes) * samples_per_route} total samples\")\n",
    "    \n",
    "    training_data = []\n",
    "    \n",
    "    # Progress tracking\n",
    "    total_routes = len(routes)\n",
    "    \n",
    "    for route_idx, (origin_lat, origin_lng, dest_lat, dest_lng) in enumerate(routes):\n",
    "        print(f\"   Route {route_idx + 1}/{total_routes}: ({origin_lat:.4f}, {origin_lng:.4f}) → ({dest_lat:.4f}, {dest_lng:.4f})\")\n",
    "        \n",
    "        # Generate samples for this route\n",
    "        base_date = datetime.datetime.now() - datetime.timedelta(days=60)\n",
    "        \n",
    "        for sample_idx in range(samples_per_route):\n",
    "            # Sample random time within last 60 days\n",
    "            sample_time = base_date + datetime.timedelta(\n",
    "                days=np.random.randint(0, 60),\n",
    "                hours=np.random.randint(6, 22),  # Business hours\n",
    "                minutes=np.random.randint(0, 60)\n",
    "            )\n",
    "            \n",
    "            # Get travel time\n",
    "            travel_time = get_google_maps_travel_time(\n",
    "                origin_lat, origin_lng, dest_lat, dest_lng, \n",
    "                sample_time, CONFIG['GOOGLE_API_KEY']\n",
    "            )\n",
    "            \n",
    "            if travel_time is None:\n",
    "                continue\n",
    "            \n",
    "            # Get weather data\n",
    "            weather_data = get_weather_data(\n",
    "                origin_lat, origin_lng, sample_time, CONFIG['WEATHER_API_KEY']\n",
    "            )\n",
    "            \n",
    "            # Create features\n",
    "            features = create_features(\n",
    "                origin_lat, origin_lng, dest_lat, dest_lng, sample_time, weather_data\n",
    "            )\n",
    "            features['travel_time_minutes'] = travel_time\n",
    "            features['route_id'] = route_idx\n",
    "            \n",
    "            training_data.append(features)\n",
    "        \n",
    "        # Show progress every 5 routes\n",
    "        if (route_idx + 1) % 5 == 0:\n",
    "            print(f\"    Completed {route_idx + 1} routes ({len(training_data)} samples collected)\")\n",
    "    \n",
    "    df = pd.DataFrame(training_data)\n",
    "    print(f\"Data collection completed! Collected {len(df)} samples\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Collect the training data\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING DATA COLLECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "training_df = collect_training_data(UDUPI_ROUTES, CONFIG['TRAINING_SAMPLES_PER_ROUTE'])\n",
    "\n",
    "# Save raw data\n",
    "training_df.to_csv('udupi_travel_time_data.csv', index=False)\n",
    "print(f\"Training data saved to 'udupi_travel_time_data.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55497abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27e10856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXPLORATORY DATA ANALYSIS\n",
      "============================================================\n",
      "Dataset Overview:\n",
      "   • Total samples: 0\n",
      "   • Features: -1\n",
      "   • Date range: 0 samples\n",
      "   • Memory usage: 0.0 MB\n",
      "\n",
      " Travel Time Statistics:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'travel_time_minutes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'travel_time_minutes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   • Memory usage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_df\u001b[38;5;241m.\u001b[39mmemory_usage(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1024\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Travel Time Statistics:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(training_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtravel_time_minutes\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create visualizations\u001b[39;00m\n\u001b[0;32m     20\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'travel_time_minutes'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5: EXPLORATORY DATA ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"   • Total samples: {len(training_df)}\")\n",
    "print(f\"   • Features: {len(training_df.columns) - 1}\")\n",
    "print(f\"   • Date range: {training_df.shape[0]} samples\")\n",
    "print(f\"   • Memory usage: {training_df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB\")\n",
    "\n",
    "print(\"\\n Travel Time Statistics:\")\n",
    "print(training_df['travel_time_minutes'].describe())\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Udupi Delivery Route Travel Time Analysis', fontsize=16)\n",
    "\n",
    "# 1. Travel time distribution\n",
    "axes[0, 0].hist(training_df['travel_time_minutes'], bins=50, alpha=0.7, color='skyblue')\n",
    "axes[0, 0].axvline(training_df['travel_time_minutes'].mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {training_df[\"travel_time_minutes\"].mean():.1f} min')\n",
    "axes[0, 0].set_xlabel('Travel Time (minutes)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Travel Time Distribution')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Travel time by hour\n",
    "hourly_avg = training_df.groupby('hour')['travel_time_minutes'].mean()\n",
    "axes[0, 1].plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Hour of Day')\n",
    "axes[0, 1].set_ylabel('Average Travel Time (min)')\n",
    "axes[0, 1].set_title('Travel Time by Hour')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Travel time by day of week\n",
    "dow_avg = training_df.groupby('day_of_week')['travel_time_minutes'].mean()\n",
    "dow_labels = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[0, 2].bar(range(7), dow_avg.values, color='lightcoral')\n",
    "axes[0, 2].set_xlabel('Day of Week')\n",
    "axes[0, 2].set_ylabel('Average Travel Time (min)')\n",
    "axes[0, 2].set_title('Travel Time by Day of Week')\n",
    "axes[0, 2].set_xticks(range(7))\n",
    "axes[0, 2].set_xticklabels(dow_labels)\n",
    "\n",
    "# 4. Distance vs travel time\n",
    "axes[1, 0].scatter(training_df['distance_km'], training_df['travel_time_minutes'], alpha=0.5)\n",
    "axes[1, 0].set_xlabel('Distance (km)')\n",
    "axes[1, 0].set_ylabel('Travel Time (minutes)')\n",
    "axes[1, 0].set_title('Distance vs Travel Time')\n",
    "\n",
    "# 5. Weather impact\n",
    "weather_avg = training_df.groupby('weather_condition')['travel_time_minutes'].mean()\n",
    "axes[1, 1].bar(weather_avg.index, weather_avg.values, color='lightgreen')\n",
    "axes[1, 1].set_xlabel('Weather Condition')\n",
    "axes[1, 1].set_ylabel('Average Travel Time (min)')\n",
    "axes[1, 1].set_title('Travel Time by Weather')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 6. Temperature vs travel time\n",
    "axes[1, 2].scatter(training_df['temperature'], training_df['travel_time_minutes'], alpha=0.5, color='orange')\n",
    "axes[1, 2].set_xlabel('Temperature (°C)')\n",
    "axes[1, 2].set_ylabel('Travel Time (minutes)')\n",
    "axes[1, 2].set_title('Temperature vs Travel Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\n🔗 Feature Correlations with Travel Time:\")\n",
    "correlations = training_df.corr()['travel_time_minutes'].sort_values(ascending=False)\n",
    "for feature, corr in correlations.items():\n",
    "    if feature != 'travel_time_minutes':\n",
    "        print(f\"   {feature:20s}: {corr:6.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 6: DATA PREPROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, StandardScaler, Dict]:\n",
    "    \"\"\"Preprocess the training data.\"\"\"\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(['travel_time_minutes', 'route_id'], axis=1)\n",
    "    y = df['travel_time_minutes']\n",
    "    \n",
    "    print(f\" Original features: {X.shape[1]}\")\n",
    "    \n",
    "    # Handle categorical variables\n",
    "    label_encoders = {}\n",
    "    categorical_columns = ['weather_condition']\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in X.columns:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "            print(f\"    Encoded {col}: {len(le.classes_)} categories\")\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X), \n",
    "        columns=X.columns, \n",
    "        index=X.index\n",
    "    )\n",
    "    \n",
    "    print(f\"  Scaled {X.shape[1]} numerical features\")\n",
    "    print(f\"Target variable: {y.name} (shape: {y.shape})\")\n",
    "    \n",
    "    return X_scaled, y, scaler, label_encoders\n",
    "\n",
    "# Preprocess the data\n",
    "X_processed, y_processed, feature_scaler, encoders = preprocess_data(training_df)\n",
    "\n",
    "print(f\"\\n Processed Dataset Shape: {X_processed.shape}\")\n",
    "print(f\" Feature Names: {list(X_processed.columns)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081e561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 7: MODEL TRAINING AND COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL TRAINING AND COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y_processed, test_size=0.2, random_state=CONFIG['RANDOM_SEED']\n",
    ")\n",
    "\n",
    "print(f\" Training set: {X_train.shape}\")\n",
    "print(f\" Test set: {X_test.shape}\")\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=CONFIG['RANDOM_SEED'],\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=8,\n",
    "        random_state=CONFIG['RANDOM_SEED'],\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'LightGBM': lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=CONFIG['RANDOM_SEED'],\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111db095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Training {name}...\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, \n",
    "                               scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    cv_mae = -cv_scores.mean()\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'train_mae': train_mae,\n",
    "        'test_mae': test_mae,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2,\n",
    "        'cv_mae': cv_mae,\n",
    "        'predictions': y_pred_test\n",
    "    }\n",
    "    \n",
    "    print(f\"    {name} Results:\")\n",
    "    print(f\"      • Train MAE: {train_mae:.2f} min\")\n",
    "    print(f\"      • Test MAE:  {test_mae:.2f} min\")\n",
    "    print(f\"      • Test RMSE: {test_rmse:.2f} min\")\n",
    "    print(f\"      • Test R²:   {test_r2:.3f}\")\n",
    "    print(f\"      • CV MAE:    {cv_mae:.2f} min\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 8: MODEL COMPARISON AND SELECTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON AND SELECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Test MAE': [results[model]['test_mae'] for model in results.keys()],\n",
    "    'Test RMSE': [results[model]['test_rmse'] for model in results.keys()],\n",
    "    'Test R²': [results[model]['test_r2'] for model in results.keys()],\n",
    "    'CV MAE': [results[model]['cv_mae'] for model in results.keys()]\n",
    "})\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Select best model based on test MAE\n",
    "best_model_name = comparison_df.loc[comparison_df['Test MAE'].idxmin(), 'Model']\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\n Best Model: {best_model_name}\")\n",
    "print(f\"   • Test MAE: {results[best_model_name]['test_mae']:.2f} minutes\")\n",
    "print(f\"   • Test R²: {results[best_model_name]['test_r2']:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce72024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 9: MODEL ANALYSIS AND VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL ANALYSIS AND VISUALIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Feature importance (for tree-based models)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_processed.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\" Top 10 Most Important Features:\")\n",
    "    for idx, row in feature_importance.head(10).iterrows():\n",
    "        print(f\"   {row['feature']:20s}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    top_features = feature_importance.head(10)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 10 Feature Importances')\n",
    "    plt.gca().invert_yaxis()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d97a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual plot\n",
    "plt.subplot(2, 2, 2)\n",
    "y_pred_best = results[best_model_name]['predictions']\n",
    "plt.scatter(y_test, y_pred_best, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Travel Time (min)')\n",
    "plt.ylabel('Predicted Travel Time (min)')\n",
    "plt.title(f'{best_model_name}: Predictions vs Actual')\n",
    "\n",
    "# Residuals plot\n",
    "plt.subplot(2, 2, 3)\n",
    "residuals = y_test - y_pred_best\n",
    "plt.scatter(y_pred_best, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Travel Time (min)')\n",
    "plt.ylabel('Residuals (min)')\n",
    "plt.title('Residuals Plot')\n",
    "\n",
    "# Model comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "model_names = list(results.keys())\n",
    "test_maes = [results[model]['test_mae'] for model in model_names]\n",
    "plt.bar(model_names, test_maes, color=['gold' if model == best_model_name else 'lightblue' for model in model_names])\n",
    "plt.ylabel('Test MAE (minutes)')\n",
    "plt.title('Model Comparison (Test MAE)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d9d66b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING THE BEST MODEL\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SECTION 10: SAVE THE BEST MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAVING THE BEST MODEL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create model package\n",
    "model_package = {\n",
    "    'model': best_model,\n",
    "    'scaler': feature_scaler,\n",
    "    'label_encoders': encoders,\n",
    "    'feature_columns': list(X_processed.columns),\n",
    "    'model_name': best_model_name,\n",
    "    'training_metrics': {\n",
    "        'test_mae': results[best_model_name]['test_mae'],\n",
    "        'test_rmse': results[best_model_name]['test_rmse'],\n",
    "        'test_r2': results[best_model_name]['test_r2'],\n",
    "        'cv_mae': results[best_model_name]['cv_mae']\n",
    "    },\n",
    "    'training_date': datetime.datetime.now().isoformat(),\n",
    "    'training_samples': len(training_df),\n",
    "    'feature_importance': feature_importance.to_dict('records') if hasattr(best_model, 'feature_importances_') else None\n",
    "}\n",
    "\n",
    "# Save model\n",
    "model_filename = f'udupi_travel_time_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc1f536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
